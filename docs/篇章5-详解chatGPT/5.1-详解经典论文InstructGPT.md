# 详解经典论文InstructGPT

[InstructGPT经典论文链接](https://arxiv.org/pdf/2203.02155)
[论文中文版本](http://www.liaolinchun.com/archives/instructgpt-translate)
[文章讲解](https://huggingface.co/blog/zh/rlhf)
[视频讲解](https://www.bilibili.com/video/BV1fA411Z772/?spm_id_from=pageDriver&vd_source=35175d2a7dcd61ae778163f55d8e1297)

  ChatGPT四阶段
  预训练
  有监督微调
  奖励建模
  强化学习

  # 大模型alignment问题
  InstructGPT和后面的ChatGPT，都是OpenAI在大模型alignment问题上的研究成果。
  就是说，模型的输出，跟我们期待的，可能有所不一致。这个跟人类的需求的对齐问题，就是所谓的alignment问题。
  李宏毅老师的视频[Chat GPT是怎麼煉成的 - GPT 社會化的過程](https://www.youtube.com/watch?v=e0aKI2GGZNg)中把对大模型的跟人类需求一致性的改善过程，称为大模型的“社会化”过程，十分的形象。
  大模型在预训练过程中见识了各种各样的数据，因此针对一个prompt会输出什么东西，也可能是多种多样的，
  但是预训练数据中出现的数据模式，不代表都是人类在使用模型时希望看到的模式，因此需要一个社会化的过程，来规范模型的“言行举止”。
